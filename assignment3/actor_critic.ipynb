{
 "cells": [
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-29T16:22:42.401852Z",
     "start_time": "2024-12-29T16:22:41.530424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import gymnasium as gym\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from assignment3.training_loop import training_loop\n",
    "from assignment3.models import PolicyNetwork, ValueNetwork\n",
    "from assignment3.dim_alignment import ENV_ACT_DIM, max_output_dim, max_input_dim\n",
    "from assignment3.optuna_search import OptunaSearch, StudyFloatParamRange\n",
    "from assignment3.device import get_device"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T16:22:42.407096Z",
     "start_time": "2024-12-29T16:22:42.404359Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generalized_actor_critic(\n",
    "        env_name,\n",
    "        input_dim,\n",
    "        output_dim,\n",
    "        hidden_sizes_theta,\n",
    "        hidden_sizes_w,\n",
    "        dropout_layers,\n",
    "        alpha_theta=0.001,\n",
    "        alpha_w=0.001,\n",
    "        episodes=500,\n",
    "        gamma=0.99,\n",
    "        dropout_p=0.7,\n",
    "        log_dir=\"runs/actor_critic\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Train a policy and value network using Actor-Critic, with padded inputs/outputs.\n",
    "    \"\"\"\n",
    "    device = get_device()\n",
    "    env = gym.make(env_name)\n",
    "    writer = SummaryWriter(log_dir=f\"{log_dir}_{env_name}\")\n",
    "\n",
    "    policy_network = PolicyNetwork(input_dim, hidden_sizes_theta, output_dim, dropout_layers, dropout_p).to(device)\n",
    "    value_network = ValueNetwork(input_dim, hidden_sizes_w).to(device)\n",
    "\n",
    "    policy_optimizer = optim.Adam(policy_network.parameters(), lr=alpha_theta)\n",
    "    value_optimizer = optim.Adam(value_network.parameters(), lr=alpha_w)\n",
    "\n",
    "    rewards_per_episode = []\n",
    "\n",
    "    # Identify the actual dimensionalities for this env\n",
    "    actual_act_dim = ENV_ACT_DIM[env_name]\n",
    "\n",
    "    train_time = training_loop(\n",
    "        input_dim=input_dim,\n",
    "        actual_act_dim=actual_act_dim,\n",
    "        policy_network=policy_network,\n",
    "        value_network=value_network,\n",
    "        policy_optimizer=policy_optimizer,\n",
    "        value_optimizer=value_optimizer,\n",
    "        env=env,\n",
    "        env_name=env_name,\n",
    "        episodes=episodes,\n",
    "        gamma=gamma,\n",
    "        writer=writer,\n",
    "        rewards_per_episode=rewards_per_episode,\n",
    "    )\n",
    "\n",
    "    writer.close()\n",
    "    env.close()\n",
    "\n",
    "    return policy_network, value_network, rewards_per_episode, train_time"
   ],
   "id": "39d88d020add6902",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T16:22:42.437974Z",
     "start_time": "2024-12-29T16:22:42.435466Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# TODO: to find the best hyperparameters for each environment, initialize different ranges and params for each env separately\n",
    "\n",
    "episodes = 2000\n",
    "n_trials = 10\n",
    "overall_results = {}\n",
    "\n",
    "# Common hidden sizes options\n",
    "hidden_sizes_theta_values = [\"[16, 32, 16]\", \"[32, 64, 32]\"]\n",
    "hidden_sizes_w_values = [\"[16, 32, 16]\", \"[32, 64, 32]\"]\n",
    "dropout_layers = [1]\n",
    "\n",
    "# Define your search ranges\n",
    "gamma_values = StudyFloatParamRange(low=0.95, high=0.99, step=0.01)\n",
    "alpha_theta_values = StudyFloatParamRange(low=0.0005, high=0.0008, step=0.0001)\n",
    "alpha_w_values = StudyFloatParamRange(low=0.0005, high=0.0008, step=0.0001)\n",
    "dropout_p_values = StudyFloatParamRange(low=0.2, high=0.5, step=0.1)"
   ],
   "id": "654c9ac89165a89f",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T16:22:42.443480Z",
     "start_time": "2024-12-29T16:22:42.441218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_experiment(env_name,\n",
    "                   hidden_sizes_theta_values=hidden_sizes_theta_values,\n",
    "                   hidden_sizes_w_values=hidden_sizes_w_values,\n",
    "                   dropout_layers=dropout_layers,\n",
    "                   gamma_values=gamma_values,\n",
    "                   alpha_theta_values=alpha_theta_values,\n",
    "                   alpha_w_values=alpha_w_values,\n",
    "                   dropout_p_values=dropout_p_values,\n",
    "                   episodes=episodes,\n",
    "                   n_trials=n_trials):\n",
    "    optuna_search = OptunaSearch(\n",
    "        train_function=generalized_actor_critic,\n",
    "        env_name=env_name,\n",
    "        max_input_dim=max_input_dim,\n",
    "        max_output_dim=max_output_dim,\n",
    "        hidden_sizes_theta_values=hidden_sizes_theta_values,\n",
    "        hidden_sizes_w_values=hidden_sizes_w_values,\n",
    "        dropout_layers=dropout_layers,\n",
    "        gamma_values=gamma_values,\n",
    "        alpha_theta_values=alpha_theta_values,\n",
    "        alpha_w_values=alpha_w_values,\n",
    "        dropout_p_values=dropout_p_values,\n",
    "        episodes=episodes,\n",
    "    )\n",
    "    best_policy, best_value, best_params, best_reward, study = optuna_search.optuna_search_for_env(n_trials=n_trials,\n",
    "                                                                                                   study_name=f\"{env_name}_actor_critic_study\")\n",
    "\n",
    "    print(\"\\nDone! Best parameters found by Optuna:\", best_params)\n",
    "    print(\"Best reward from Optuna:\", best_reward)\n",
    "\n",
    "    # save networks to pretrained_models\n",
    "    torch.save(best_policy.state_dict(), f\"pretrained_models/{env_name}_policy.pth\")\n",
    "    torch.save(best_value.state_dict(), f\"pretrained_models/{env_name}_value.pth\")"
   ],
   "id": "3ceaf2c534e0d102",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T16:36:21.955614Z",
     "start_time": "2024-12-29T16:22:42.452607Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Launch the search on, say, CartPole-v1\n",
    "run_experiment(\"CartPole-v1\", episodes=1000)"
   ],
   "id": "925b1dfc05860767",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-29 18:22:42,453] A new study created in memory with name: CartPole-v1_actor_critic_study\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[OPTUNA Trial 0] Env=CartPole-v1:\n",
      "        hidden_sizes_theta=[32, 64, 32], hidden_sizes_w=[32, 64, 32],\n",
      "         gamma=0.99, dropout_p=0.4,\n",
      "         alpha_theta=0.0006000000000000001, alpha_w=0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1000/1000 [01:48<00:00,  9.22episode/s, Avg Reward(100)=309.83]\n",
      "[I 2024-12-29 18:24:31,452] Trial 0 finished with value: 1000.0 and parameters: {'hidden_sizes_theta': '[32, 64, 32]', 'hidden_sizes_w': '[32, 64, 32]', 'gamma': 0.99, 'alpha_theta': 0.0006000000000000001, 'alpha_w': 0.0008, 'dropout_p': 0.4}. Best is trial 0 with value: 1000.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[OPTUNA Trial 1] Env=CartPole-v1:\n",
      "        hidden_sizes_theta=[32, 64, 32], hidden_sizes_w=[32, 64, 32],\n",
      "         gamma=0.96, dropout_p=0.2,\n",
      "         alpha_theta=0.0008, alpha_w=0.0006000000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1000/1000 [00:46<00:00, 21.65episode/s, Avg Reward(100)=233.25]\n",
      "[I 2024-12-29 18:25:17,652] Trial 1 finished with value: 1000.0 and parameters: {'hidden_sizes_theta': '[32, 64, 32]', 'hidden_sizes_w': '[32, 64, 32]', 'gamma': 0.96, 'alpha_theta': 0.0008, 'alpha_w': 0.0006000000000000001, 'dropout_p': 0.2}. Best is trial 0 with value: 1000.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[OPTUNA Trial 2] Env=CartPole-v1:\n",
      "        hidden_sizes_theta=[32, 64, 32], hidden_sizes_w=[32, 64, 32],\n",
      "         gamma=0.99, dropout_p=0.2,\n",
      "         alpha_theta=0.0005, alpha_w=0.0006000000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  86%|████████▋ | 863/1000 [01:31<00:14,  9.39episode/s, Avg Reward(100)=223.36]\n",
      "[I 2024-12-29 18:26:49,531] Trial 2 finished with value: 864.0 and parameters: {'hidden_sizes_theta': '[32, 64, 32]', 'hidden_sizes_w': '[32, 64, 32]', 'gamma': 0.99, 'alpha_theta': 0.0005, 'alpha_w': 0.0006000000000000001, 'dropout_p': 0.2}. Best is trial 2 with value: 864.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solved CartPole-v1 in 864 episodes!\n",
      "\n",
      "[OPTUNA Trial 3] Env=CartPole-v1:\n",
      "        hidden_sizes_theta=[16, 32, 16], hidden_sizes_w=[32, 64, 32],\n",
      "         gamma=0.97, dropout_p=0.4,\n",
      "         alpha_theta=0.0008, alpha_w=0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1000/1000 [01:17<00:00, 12.84episode/s, Avg Reward(100)=175.56]\n",
      "[I 2024-12-29 18:28:07,396] Trial 3 finished with value: 1000.0 and parameters: {'hidden_sizes_theta': '[16, 32, 16]', 'hidden_sizes_w': '[32, 64, 32]', 'gamma': 0.97, 'alpha_theta': 0.0008, 'alpha_w': 0.0007, 'dropout_p': 0.4}. Best is trial 2 with value: 864.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[OPTUNA Trial 4] Env=CartPole-v1:\n",
      "        hidden_sizes_theta=[16, 32, 16], hidden_sizes_w=[32, 64, 32],\n",
      "         gamma=0.98, dropout_p=0.30000000000000004,\n",
      "         alpha_theta=0.0006000000000000001, alpha_w=0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1000/1000 [01:02<00:00, 15.96episode/s, Avg Reward(100)=386.59]\n",
      "[I 2024-12-29 18:29:10,068] Trial 4 finished with value: 1000.0 and parameters: {'hidden_sizes_theta': '[16, 32, 16]', 'hidden_sizes_w': '[32, 64, 32]', 'gamma': 0.98, 'alpha_theta': 0.0006000000000000001, 'alpha_w': 0.0008, 'dropout_p': 0.30000000000000004}. Best is trial 2 with value: 864.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[OPTUNA Trial 5] Env=CartPole-v1:\n",
      "        hidden_sizes_theta=[32, 64, 32], hidden_sizes_w=[32, 64, 32],\n",
      "         gamma=0.97, dropout_p=0.30000000000000004,\n",
      "         alpha_theta=0.0007, alpha_w=0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  95%|█████████▍| 947/1000 [01:31<00:05, 10.33episode/s, Avg Reward(100)=384.07]\n",
      "[I 2024-12-29 18:30:41,744] Trial 5 finished with value: 948.0 and parameters: {'hidden_sizes_theta': '[32, 64, 32]', 'hidden_sizes_w': '[32, 64, 32]', 'gamma': 0.97, 'alpha_theta': 0.0007, 'alpha_w': 0.0005, 'dropout_p': 0.30000000000000004}. Best is trial 2 with value: 864.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solved CartPole-v1 in 948 episodes!\n",
      "\n",
      "[OPTUNA Trial 6] Env=CartPole-v1:\n",
      "        hidden_sizes_theta=[32, 64, 32], hidden_sizes_w=[16, 32, 16],\n",
      "         gamma=0.96, dropout_p=0.30000000000000004,\n",
      "         alpha_theta=0.0007, alpha_w=0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1000/1000 [00:22<00:00, 44.76episode/s, Avg Reward(100)=9.47]  \n",
      "[I 2024-12-29 18:31:04,092] Trial 6 finished with value: 1000.0 and parameters: {'hidden_sizes_theta': '[32, 64, 32]', 'hidden_sizes_w': '[16, 32, 16]', 'gamma': 0.96, 'alpha_theta': 0.0007, 'alpha_w': 0.0008, 'dropout_p': 0.30000000000000004}. Best is trial 2 with value: 864.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[OPTUNA Trial 7] Env=CartPole-v1:\n",
      "        hidden_sizes_theta=[16, 32, 16], hidden_sizes_w=[32, 64, 32],\n",
      "         gamma=0.98, dropout_p=0.4,\n",
      "         alpha_theta=0.0007, alpha_w=0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  88%|████████▊ | 884/1000 [01:38<00:12,  8.99episode/s, Avg Reward(100)=225.84]\n",
      "[I 2024-12-29 18:32:42,416] Trial 7 finished with value: 885.0 and parameters: {'hidden_sizes_theta': '[16, 32, 16]', 'hidden_sizes_w': '[32, 64, 32]', 'gamma': 0.98, 'alpha_theta': 0.0007, 'alpha_w': 0.0008, 'dropout_p': 0.4}. Best is trial 2 with value: 864.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solved CartPole-v1 in 885 episodes!\n",
      "\n",
      "[OPTUNA Trial 8] Env=CartPole-v1:\n",
      "        hidden_sizes_theta=[16, 32, 16], hidden_sizes_w=[16, 32, 16],\n",
      "         gamma=0.98, dropout_p=0.2,\n",
      "         alpha_theta=0.0006000000000000001, alpha_w=0.0006000000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1000/1000 [01:33<00:00, 10.69episode/s, Avg Reward(100)=364.54]\n",
      "[I 2024-12-29 18:34:15,972] Trial 8 finished with value: 1000.0 and parameters: {'hidden_sizes_theta': '[16, 32, 16]', 'hidden_sizes_w': '[16, 32, 16]', 'gamma': 0.98, 'alpha_theta': 0.0006000000000000001, 'alpha_w': 0.0006000000000000001, 'dropout_p': 0.2}. Best is trial 2 with value: 864.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[OPTUNA Trial 9] Env=CartPole-v1:\n",
      "        hidden_sizes_theta=[16, 32, 16], hidden_sizes_w=[32, 64, 32],\n",
      "         gamma=0.98, dropout_p=0.2,\n",
      "         alpha_theta=0.0008, alpha_w=0.0006000000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  76%|███████▌  | 759/1000 [01:00<00:19, 12.60episode/s, Avg Reward(100)=366.82]\n",
      "[I 2024-12-29 18:35:16,218] Trial 9 finished with value: 760.0 and parameters: {'hidden_sizes_theta': '[16, 32, 16]', 'hidden_sizes_w': '[32, 64, 32]', 'gamma': 0.98, 'alpha_theta': 0.0008, 'alpha_w': 0.0006000000000000001, 'dropout_p': 0.2}. Best is trial 9 with value: 760.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solved CartPole-v1 in 760 episodes!\n",
      "\n",
      "[OPTUNA] Best trial: trail 9\n",
      "  Value (Reward): 760.00\n",
      "  Params: {'hidden_sizes_theta': '[16, 32, 16]', 'hidden_sizes_w': '[32, 64, 32]', 'gamma': 0.98, 'alpha_theta': 0.0008, 'alpha_w': 0.0006000000000000001, 'dropout_p': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1000/1000 [01:05<00:00, 15.21episode/s, Avg Reward(100)=174.44]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Optuna search time for CartPole-v1: 819.50s\n",
      "\n",
      "Done! Best parameters found by Optuna: {'hidden_sizes_theta': '[16, 32, 16]', 'hidden_sizes_w': '[32, 64, 32]', 'gamma': 0.98, 'alpha_theta': 0.0008, 'alpha_w': 0.0006000000000000001, 'dropout_p': 0.2}\n",
      "Best reward from Optuna: 760.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T16:44:12.367147Z",
     "start_time": "2024-12-29T16:36:21.984772Z"
    }
   },
   "cell_type": "code",
   "source": "run_experiment(\"Acrobot-v1\", episodes=500)",
   "id": "60e3b164384bc6a2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-29 18:36:21,985] A new study created in memory with name: Acrobot-v1_actor_critic_study\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[OPTUNA Trial 0] Env=Acrobot-v1:\n",
      "        hidden_sizes_theta=[32, 64, 32], hidden_sizes_w=[16, 32, 16],\n",
      "         gamma=0.99, dropout_p=0.30000000000000004,\n",
      "         alpha_theta=0.0006000000000000001, alpha_w=0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 100/500 [00:05<00:20, 19.48episode/s, Avg Reward(100)=-101.64]\n",
      "[I 2024-12-29 18:36:27,128] Trial 0 finished with value: 101.0 and parameters: {'hidden_sizes_theta': '[32, 64, 32]', 'hidden_sizes_w': '[16, 32, 16]', 'gamma': 0.99, 'alpha_theta': 0.0006000000000000001, 'alpha_w': 0.0008, 'dropout_p': 0.30000000000000004}. Best is trial 0 with value: 101.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solved Acrobot-v1 in 101 episodes!\n",
      "\n",
      "[OPTUNA Trial 1] Env=Acrobot-v1:\n",
      "        hidden_sizes_theta=[32, 64, 32], hidden_sizes_w=[16, 32, 16],\n",
      "         gamma=0.96, dropout_p=0.4,\n",
      "         alpha_theta=0.0006000000000000001, alpha_w=0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██▏       | 107/500 [00:06<00:23, 16.88episode/s, Avg Reward(100)=-118.61]\n",
      "[I 2024-12-29 18:36:33,471] Trial 1 finished with value: 108.0 and parameters: {'hidden_sizes_theta': '[32, 64, 32]', 'hidden_sizes_w': '[16, 32, 16]', 'gamma': 0.96, 'alpha_theta': 0.0006000000000000001, 'alpha_w': 0.0007, 'dropout_p': 0.4}. Best is trial 0 with value: 101.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solved Acrobot-v1 in 108 episodes!\n",
      "\n",
      "[OPTUNA Trial 2] Env=Acrobot-v1:\n",
      "        hidden_sizes_theta=[32, 64, 32], hidden_sizes_w=[16, 32, 16],\n",
      "         gamma=0.98, dropout_p=0.2,\n",
      "         alpha_theta=0.0006000000000000001, alpha_w=0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 500/500 [02:01<00:00,  4.10episode/s, Avg Reward(100)=-500.00]\n",
      "[I 2024-12-29 18:38:35,313] Trial 2 finished with value: 500.0 and parameters: {'hidden_sizes_theta': '[32, 64, 32]', 'hidden_sizes_w': '[16, 32, 16]', 'gamma': 0.98, 'alpha_theta': 0.0006000000000000001, 'alpha_w': 0.0005, 'dropout_p': 0.2}. Best is trial 0 with value: 101.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[OPTUNA Trial 3] Env=Acrobot-v1:\n",
      "        hidden_sizes_theta=[16, 32, 16], hidden_sizes_w=[32, 64, 32],\n",
      "         gamma=0.96, dropout_p=0.2,\n",
      "         alpha_theta=0.0006000000000000001, alpha_w=0.0006000000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  47%|████▋     | 235/500 [00:23<00:26,  9.94episode/s, Avg Reward(100)=-140.40]\n",
      "[I 2024-12-29 18:38:58,959] Trial 3 finished with value: 236.0 and parameters: {'hidden_sizes_theta': '[16, 32, 16]', 'hidden_sizes_w': '[32, 64, 32]', 'gamma': 0.96, 'alpha_theta': 0.0006000000000000001, 'alpha_w': 0.0006000000000000001, 'dropout_p': 0.2}. Best is trial 0 with value: 101.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solved Acrobot-v1 in 236 episodes!\n",
      "\n",
      "[OPTUNA Trial 4] Env=Acrobot-v1:\n",
      "        hidden_sizes_theta=[32, 64, 32], hidden_sizes_w=[16, 32, 16],\n",
      "         gamma=0.95, dropout_p=0.5,\n",
      "         alpha_theta=0.0008, alpha_w=0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 500/500 [02:02<00:00,  4.09episode/s, Avg Reward(100)=-500.00]\n",
      "[I 2024-12-29 18:41:01,128] Trial 4 finished with value: 500.0 and parameters: {'hidden_sizes_theta': '[32, 64, 32]', 'hidden_sizes_w': '[16, 32, 16]', 'gamma': 0.95, 'alpha_theta': 0.0008, 'alpha_w': 0.0008, 'dropout_p': 0.5}. Best is trial 0 with value: 101.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[OPTUNA Trial 5] Env=Acrobot-v1:\n",
      "        hidden_sizes_theta=[32, 64, 32], hidden_sizes_w=[32, 64, 32],\n",
      "         gamma=0.98, dropout_p=0.2,\n",
      "         alpha_theta=0.0007, alpha_w=0.0006000000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██        | 106/500 [00:06<00:25, 15.49episode/s, Avg Reward(100)=-128.25]\n",
      "[I 2024-12-29 18:41:07,977] Trial 5 finished with value: 107.0 and parameters: {'hidden_sizes_theta': '[32, 64, 32]', 'hidden_sizes_w': '[32, 64, 32]', 'gamma': 0.98, 'alpha_theta': 0.0007, 'alpha_w': 0.0006000000000000001, 'dropout_p': 0.2}. Best is trial 0 with value: 101.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solved Acrobot-v1 in 107 episodes!\n",
      "\n",
      "[OPTUNA Trial 6] Env=Acrobot-v1:\n",
      "        hidden_sizes_theta=[32, 64, 32], hidden_sizes_w=[16, 32, 16],\n",
      "         gamma=0.98, dropout_p=0.30000000000000004,\n",
      "         alpha_theta=0.0005, alpha_w=0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  49%|████▉     | 245/500 [00:38<00:40,  6.36episode/s, Avg Reward(100)=-254.41]\n",
      "[I 2024-12-29 18:41:46,503] Trial 6 finished with value: 246.0 and parameters: {'hidden_sizes_theta': '[32, 64, 32]', 'hidden_sizes_w': '[16, 32, 16]', 'gamma': 0.98, 'alpha_theta': 0.0005, 'alpha_w': 0.0007, 'dropout_p': 0.30000000000000004}. Best is trial 0 with value: 101.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solved Acrobot-v1 in 246 episodes!\n",
      "\n",
      "[OPTUNA Trial 7] Env=Acrobot-v1:\n",
      "        hidden_sizes_theta=[16, 32, 16], hidden_sizes_w=[32, 64, 32],\n",
      "         gamma=0.95, dropout_p=0.30000000000000004,\n",
      "         alpha_theta=0.0008, alpha_w=0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 500/500 [01:59<00:00,  4.17episode/s, Avg Reward(100)=-500.00]\n",
      "[I 2024-12-29 18:43:46,504] Trial 7 finished with value: 500.0 and parameters: {'hidden_sizes_theta': '[16, 32, 16]', 'hidden_sizes_w': '[32, 64, 32]', 'gamma': 0.95, 'alpha_theta': 0.0008, 'alpha_w': 0.0005, 'dropout_p': 0.30000000000000004}. Best is trial 0 with value: 101.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[OPTUNA Trial 8] Env=Acrobot-v1:\n",
      "        hidden_sizes_theta=[16, 32, 16], hidden_sizes_w=[16, 32, 16],\n",
      "         gamma=0.98, dropout_p=0.2,\n",
      "         alpha_theta=0.0008, alpha_w=0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|██▎       | 118/500 [00:07<00:23, 16.09episode/s, Avg Reward(100)=-133.23]\n",
      "[I 2024-12-29 18:43:53,841] Trial 8 finished with value: 119.0 and parameters: {'hidden_sizes_theta': '[16, 32, 16]', 'hidden_sizes_w': '[16, 32, 16]', 'gamma': 0.98, 'alpha_theta': 0.0008, 'alpha_w': 0.0007, 'dropout_p': 0.2}. Best is trial 0 with value: 101.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solved Acrobot-v1 in 119 episodes!\n",
      "\n",
      "[OPTUNA Trial 9] Env=Acrobot-v1:\n",
      "        hidden_sizes_theta=[16, 32, 16], hidden_sizes_w=[32, 64, 32],\n",
      "         gamma=0.99, dropout_p=0.2,\n",
      "         alpha_theta=0.0007, alpha_w=0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██        | 105/500 [00:05<00:22, 17.68episode/s, Avg Reward(100)=-115.45]\n",
      "[I 2024-12-29 18:43:59,781] Trial 9 finished with value: 106.0 and parameters: {'hidden_sizes_theta': '[16, 32, 16]', 'hidden_sizes_w': '[32, 64, 32]', 'gamma': 0.99, 'alpha_theta': 0.0007, 'alpha_w': 0.0008, 'dropout_p': 0.2}. Best is trial 0 with value: 101.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solved Acrobot-v1 in 106 episodes!\n",
      "\n",
      "[OPTUNA] Best trial: trail 0\n",
      "  Value (Reward): 101.00\n",
      "  Params: {'hidden_sizes_theta': '[32, 64, 32]', 'hidden_sizes_w': '[16, 32, 16]', 'gamma': 0.99, 'alpha_theta': 0.0006000000000000001, 'alpha_w': 0.0008, 'dropout_p': 0.30000000000000004}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  37%|███▋      | 185/500 [00:12<00:21, 14.71episode/s, Avg Reward(100)=-167.91]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solved Acrobot-v1 in 186 episodes!\n",
      "\n",
      "Total Optuna search time for Acrobot-v1: 470.38s\n",
      "\n",
      "Done! Best parameters found by Optuna: {'hidden_sizes_theta': '[32, 64, 32]', 'hidden_sizes_w': '[16, 32, 16]', 'gamma': 0.99, 'alpha_theta': 0.0006000000000000001, 'alpha_w': 0.0008, 'dropout_p': 0.30000000000000004}\n",
      "Best reward from Optuna: 101.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T19:05:32.878876Z",
     "start_time": "2024-12-29T16:44:12.390765Z"
    }
   },
   "cell_type": "code",
   "source": "run_experiment(\"MountainCarContinuous-v0\", episodes=1500, hidden_sizes_theta_values = [\"[32, 64, 32]\", \"[32, 128, 32]\"], hidden_sizes_w_values = [\"[32, 64, 32]\", \"[32, 128, 32]\"])\n",
   "id": "a717bddf1403f884",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-29 18:44:12,391] A new study created in memory with name: MountainCarContinuous-v0_actor_critic_study\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[OPTUNA Trial 0] Env=MountainCarContinuous-v0:\n",
      "        hidden_sizes_theta=[32, 128, 32], hidden_sizes_w=[32, 128, 32],\n",
      "         gamma=0.99, dropout_p=0.4,\n",
      "         alpha_theta=0.0007, alpha_w=0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1500/1500 [13:23<00:00,  1.87episode/s, Avg Reward(100)=-19.80]\n",
      "[I 2024-12-29 18:57:35,889] Trial 0 finished with value: 1500.0 and parameters: {'hidden_sizes_theta': '[32, 128, 32]', 'hidden_sizes_w': '[32, 128, 32]', 'gamma': 0.99, 'alpha_theta': 0.0007, 'alpha_w': 0.0007, 'dropout_p': 0.4}. Best is trial 0 with value: 1500.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[OPTUNA Trial 1] Env=MountainCarContinuous-v0:\n",
      "        hidden_sizes_theta=[32, 64, 32], hidden_sizes_w=[32, 128, 32],\n",
      "         gamma=0.95, dropout_p=0.4,\n",
      "         alpha_theta=0.0006000000000000001, alpha_w=0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1500/1500 [13:29<00:00,  1.85episode/s, Avg Reward(100)=-24.83]\n",
      "[I 2024-12-29 19:11:05,422] Trial 1 finished with value: 1500.0 and parameters: {'hidden_sizes_theta': '[32, 64, 32]', 'hidden_sizes_w': '[32, 128, 32]', 'gamma': 0.95, 'alpha_theta': 0.0006000000000000001, 'alpha_w': 0.0007, 'dropout_p': 0.4}. Best is trial 0 with value: 1500.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[OPTUNA Trial 2] Env=MountainCarContinuous-v0:\n",
      "        hidden_sizes_theta=[32, 64, 32], hidden_sizes_w=[32, 64, 32],\n",
      "         gamma=0.98, dropout_p=0.5,\n",
      "         alpha_theta=0.0007, alpha_w=0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1500/1500 [10:33<00:00,  2.37episode/s, Avg Reward(100)=-20.36]\n",
      "[I 2024-12-29 19:21:38,555] Trial 2 finished with value: 1500.0 and parameters: {'hidden_sizes_theta': '[32, 64, 32]', 'hidden_sizes_w': '[32, 64, 32]', 'gamma': 0.98, 'alpha_theta': 0.0007, 'alpha_w': 0.0007, 'dropout_p': 0.5}. Best is trial 0 with value: 1500.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[OPTUNA Trial 3] Env=MountainCarContinuous-v0:\n",
      "        hidden_sizes_theta=[32, 64, 32], hidden_sizes_w=[32, 128, 32],\n",
      "         gamma=0.98, dropout_p=0.4,\n",
      "         alpha_theta=0.0007, alpha_w=0.0006000000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1500/1500 [13:16<00:00,  1.88episode/s, Avg Reward(100)=-19.47]\n",
      "[I 2024-12-29 19:34:55,406] Trial 3 finished with value: 1500.0 and parameters: {'hidden_sizes_theta': '[32, 64, 32]', 'hidden_sizes_w': '[32, 128, 32]', 'gamma': 0.98, 'alpha_theta': 0.0007, 'alpha_w': 0.0006000000000000001, 'dropout_p': 0.4}. Best is trial 0 with value: 1500.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[OPTUNA Trial 4] Env=MountainCarContinuous-v0:\n",
      "        hidden_sizes_theta=[32, 64, 32], hidden_sizes_w=[32, 64, 32],\n",
      "         gamma=0.96, dropout_p=0.2,\n",
      "         alpha_theta=0.0007, alpha_w=0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1500/1500 [10:28<00:00,  2.39episode/s, Avg Reward(100)=-22.38]\n",
      "[I 2024-12-29 19:45:24,148] Trial 4 finished with value: 1500.0 and parameters: {'hidden_sizes_theta': '[32, 64, 32]', 'hidden_sizes_w': '[32, 64, 32]', 'gamma': 0.96, 'alpha_theta': 0.0007, 'alpha_w': 0.0007, 'dropout_p': 0.2}. Best is trial 0 with value: 1500.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[OPTUNA Trial 5] Env=MountainCarContinuous-v0:\n",
      "        hidden_sizes_theta=[32, 128, 32], hidden_sizes_w=[32, 64, 32],\n",
      "         gamma=0.98, dropout_p=0.30000000000000004,\n",
      "         alpha_theta=0.0005, alpha_w=0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1500/1500 [13:01<00:00,  1.92episode/s, Avg Reward(100)=-21.71]\n",
      "[I 2024-12-29 19:58:25,197] Trial 5 finished with value: 1500.0 and parameters: {'hidden_sizes_theta': '[32, 128, 32]', 'hidden_sizes_w': '[32, 64, 32]', 'gamma': 0.98, 'alpha_theta': 0.0005, 'alpha_w': 0.0008, 'dropout_p': 0.30000000000000004}. Best is trial 0 with value: 1500.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[OPTUNA Trial 6] Env=MountainCarContinuous-v0:\n",
      "        hidden_sizes_theta=[32, 128, 32], hidden_sizes_w=[32, 128, 32],\n",
      "         gamma=0.98, dropout_p=0.4,\n",
      "         alpha_theta=0.0008, alpha_w=0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1500/1500 [13:34<00:00,  1.84episode/s, Avg Reward(100)=-20.12]\n",
      "[I 2024-12-29 20:11:59,960] Trial 6 finished with value: 1500.0 and parameters: {'hidden_sizes_theta': '[32, 128, 32]', 'hidden_sizes_w': '[32, 128, 32]', 'gamma': 0.98, 'alpha_theta': 0.0008, 'alpha_w': 0.0008, 'dropout_p': 0.4}. Best is trial 0 with value: 1500.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[OPTUNA Trial 7] Env=MountainCarContinuous-v0:\n",
      "        hidden_sizes_theta=[32, 128, 32], hidden_sizes_w=[32, 64, 32],\n",
      "         gamma=0.97, dropout_p=0.30000000000000004,\n",
      "         alpha_theta=0.0005, alpha_w=0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1500/1500 [13:13<00:00,  1.89episode/s, Avg Reward(100)=-20.87]\n",
      "[I 2024-12-29 20:25:13,520] Trial 7 finished with value: 1500.0 and parameters: {'hidden_sizes_theta': '[32, 128, 32]', 'hidden_sizes_w': '[32, 64, 32]', 'gamma': 0.97, 'alpha_theta': 0.0005, 'alpha_w': 0.0007, 'dropout_p': 0.30000000000000004}. Best is trial 0 with value: 1500.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[OPTUNA Trial 8] Env=MountainCarContinuous-v0:\n",
      "        hidden_sizes_theta=[32, 64, 32], hidden_sizes_w=[32, 128, 32],\n",
      "         gamma=0.96, dropout_p=0.2,\n",
      "         alpha_theta=0.0005, alpha_w=0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1500/1500 [13:14<00:00,  1.89episode/s, Avg Reward(100)=-22.89]\n",
      "[I 2024-12-29 20:38:27,749] Trial 8 finished with value: 1500.0 and parameters: {'hidden_sizes_theta': '[32, 64, 32]', 'hidden_sizes_w': '[32, 128, 32]', 'gamma': 0.96, 'alpha_theta': 0.0005, 'alpha_w': 0.0005, 'dropout_p': 0.2}. Best is trial 0 with value: 1500.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[OPTUNA Trial 9] Env=MountainCarContinuous-v0:\n",
      "        hidden_sizes_theta=[32, 128, 32], hidden_sizes_w=[32, 128, 32],\n",
      "         gamma=0.95, dropout_p=0.2,\n",
      "         alpha_theta=0.0005, alpha_w=0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1500/1500 [13:35<00:00,  1.84episode/s, Avg Reward(100)=-23.83]\n",
      "[I 2024-12-29 20:52:02,837] Trial 9 finished with value: 1500.0 and parameters: {'hidden_sizes_theta': '[32, 128, 32]', 'hidden_sizes_w': '[32, 128, 32]', 'gamma': 0.95, 'alpha_theta': 0.0005, 'alpha_w': 0.0008, 'dropout_p': 0.2}. Best is trial 0 with value: 1500.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[OPTUNA] Best trial: trail 0\n",
      "  Value (Reward): 1500.00\n",
      "  Params: {'hidden_sizes_theta': '[32, 128, 32]', 'hidden_sizes_w': '[32, 128, 32]', 'gamma': 0.99, 'alpha_theta': 0.0007, 'alpha_w': 0.0007, 'dropout_p': 0.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1500/1500 [13:30<00:00,  1.85episode/s, Avg Reward(100)=-20.06]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Optuna search time for MountainCarContinuous-v0: 8480.48s\n",
      "\n",
      "Done! Best parameters found by Optuna: {'hidden_sizes_theta': '[32, 128, 32]', 'hidden_sizes_w': '[32, 128, 32]', 'gamma': 0.99, 'alpha_theta': 0.0007, 'alpha_w': 0.0007, 'dropout_p': 0.4}\n",
      "Best reward from Optuna: 1500.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T19:05:32.905116Z",
     "start_time": "2024-12-29T19:05:32.903630Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "116c610e1b8afab0",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
